// This file was generated by lezer-generator. You probably shouldn't edit it.
import {LRParser} from "@lezer/lr"
import {noteContent} from "./external-tokens.js"
export const parser = LRParser.deserialize({
  version: 14,
  states: "!jQQOPOOOVOPO'#C`O[OQO'#C_OOOO'#Cc'#CcQQOPOOOaOPO,58zOOOO,58y,58yOOOO-E6a-E6aOfOPO1G.fOOOQ7+$Q7+$QOnOPO7+$QOOOQ<<Gl<<Gl",
  stateData: "s~OXPO~OYTO~OPUO~OTWO~OUYOXXO~OXZO~O",
  goto: "gWPPPX]PPaTROSTQOSQSORVS",
  nodeNames: "âš  NoteContent Document Note NoteDelimiter NoteLanguage Auto",
  maxTerm: 10,
  skippedNodes: [0],
  repeatNodeCount: 1,
  tokenData: ",p~RaYZ!W}!O!]#V#W!h#X#Y$U#Z#[$t#[#]%g#^#_%y#_#`'g#`#a(P#a#b(i#d#e)h#f#g*T#g#h*d#h#i+Y#l#m%m#m#n,X%&x%&y,_~!]OX~~!`P#T#U!c~!hOU~~!kR#`#a!t#d#e#i#g#h#o~!wP#c#d!z~!}P#^#_#Q~#TP#i#j#W~#ZP#f#g#^~#aP#X#Y#d~#iOT~~#lP#d#e#d~#rQ#[#]#x#g#h#d~#{P#T#U$O~$RP#f#g#i~$XP#f#g$[~$_P#`#a$b~$eP#T#U$h~$kP#b#c$n~$qP#Z#[#d~$wQ#c#d$[#f#g$}~%QP#c#d%T~%WP#c#d%Z~%^P#j#k%a~%dP#m#n#d~%jP#h#i%m~%pP#a#b%s~%vP#`#a#d~%|Q#T#U&S#g#h'W~&VP#j#k&Y~&]P#T#U&`~&ePT~#g#h&h~&kP#V#W&n~&qP#f#g&t~&wP#]#^&z~&}P#d#e'Q~'TP#h#i#d~'ZQ#c#d'a#l#m#d~'dP#b#c#d~'jP#c#d'm~'pP#h#i's~'vP#`#a'y~'|P#]#^'a~(SP#X#Y(V~(YP#n#o(]~(`P#X#Y(c~(fP#f#g#d~(lP#T#U(o~(rQ#f#g(x#h#i)b~({P#_#`)O~)RP#W#X)U~)XP#c#d)[~)_P#k#l'a~)eP#[#]#d~)kQ#[#]#i#m#n)q~)tP#h#i)w~)zP#[#])}~*QP#c#d'a~*WP#i#j*Z~*^Q#U#V%a#g#h'Q~*gR#[#]*p#e#f%s#k#l*|~*sP#X#Y*v~*yP#`#a%s~+PP#]#^+S~+VP#Y#Z'Q~+]S#X#Y+i#c#d%m#g#h+o#m#n+u~+lP#l#m'Q~+rP#l#m#d~+xP#d#e+{~,OP#X#Y,R~,UP#g#h&h~,[P#T#U%m~,bP%&x%&y,e~,hP%&x%&y,k~,pOY~",
  tokenizers: [0, noteContent],
  topRules: {"Document":[0,2]},
  tokenPrec: 0
})
