// This file was generated by lezer-generator. You probably shouldn't edit it.
import {LRParser} from "@lezer/lr"
import {noteContent} from "./external-tokens.js"
export const parser = LRParser.deserialize({
  version: 14,
  states: "!jQQOPOOOVOPO'#C`O[OQO'#C_OOOO'#Cc'#CcQQOPOOOaOPO,58zOOOO,58y,58yOOOO-E6a-E6aOfOPO1G.fOOOQ7+$Q7+$QOnOPO7+$QOOOQ<<Gl<<Gl",
  stateData: "s~OXPO~OYTO~OPUO~OTWO~OUYOXXO~OXZO~O",
  goto: "gWPPPX]PPaTROSTQOSQSORVS",
  nodeNames: "âš  NoteContent Document Note NoteDelimiter NoteLanguage Auto",
  maxTerm: 10,
  skippedNodes: [0],
  repeatNodeCount: 1,
  tokenData: "-V~RbYZ!Z}!O!`#V#W!k#W#X$X#X#Y$k#Z#[%Z#[#]%|#^#_&`#_#`'|#`#a(f#a#b)O#d#e)}#f#g*j#g#h*y#h#i+o#l#m&S#m#n,n%&x%&y,t~!`OX~~!cP#T#U!f~!kOU~~!nR#`#a!w#d#e#l#g#h#r~!zP#c#d!}~#QP#^#_#T~#WP#i#j#Z~#^P#f#g#a~#dP#X#Y#g~#lOT~~#oP#d#e#g~#uQ#[#]#{#g#h#g~$OP#T#U$R~$UP#f#g#l~$[P#]#^$_~$bP#Y#Z$e~$hP#Y#Z#g~$nP#f#g$q~$tP#`#a$w~$zP#T#U$}~%QP#b#c%T~%WP#Z#[#g~%^Q#c#d$q#f#g%d~%gP#c#d%j~%mP#c#d%p~%sP#j#k%v~%yP#m#n#g~&PP#h#i&S~&VP#a#b&Y~&]P#`#a#g~&cQ#T#U&i#g#h'm~&lP#j#k&o~&rP#T#U&u~&zPT~#g#h&}~'QP#V#W'T~'WP#f#g'Z~'^P#]#^'a~'dP#d#e'g~'jP#h#i#g~'pQ#c#d'v#l#m#g~'yP#b#c#g~(PP#c#d(S~(VP#h#i(Y~(]P#`#a(`~(cP#]#^'v~(iP#X#Y(l~(oP#n#o(r~(uP#X#Y(x~({P#f#g#g~)RP#T#U)U~)XQ#f#g)_#h#i)w~)bP#_#`)e~)hP#W#X)k~)nP#c#d)q~)tP#k#l'v~)zP#[#]#g~*QQ#[#]#l#m#n*W~*ZP#h#i*^~*aP#[#]*d~*gP#c#d'v~*mP#i#j*p~*sQ#U#V%v#g#h'g~*|R#[#]+V#e#f&Y#k#l+c~+YP#X#Y+]~+`P#`#a&Y~+fP#]#^+i~+lP#Y#Z'g~+rS#X#Y,O#c#d&S#g#h,U#m#n,[~,RP#l#m'g~,XP#l#m#g~,_P#d#e,b~,eP#X#Y,h~,kP#g#h&}~,qP#T#U&S~,wP%&x%&y,z~,}P%&x%&y-Q~-VOY~",
  tokenizers: [0, noteContent],
  topRules: {"Document":[0,2]},
  tokenPrec: 0
})
